{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qlee\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import common\n",
    "import sampler\n",
    "import glass\n",
    "import backbones\n",
    "import utils\n",
    "\n",
    "from perlin import perlin_mask\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import PIL\n",
    "from enum import Enum\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    }
   ],
   "source": [
    "from argparse import ArgumentParser\n",
    "\n",
    "parser = ArgumentParser(description=\"patchcore\")\n",
    "parser.add_argument('--image_size', default=288, type=int) # 288\n",
    "parser.add_argument('--resize', default=288, type=int) # 288\n",
    "parser.add_argument('--backbone', default='wideresnet50', type=str) \n",
    "parser.add_argument('--layers_to_extract_from', nargs='+', default=['layer2', 'layer3'], type=str) # 연산량에 큰 영향을 주는 파라미터 (성능만 괜찮으면 layer를 일부 제거해도 무방)\n",
    "parser.add_argument('--pretrain_embed_dimension', default=1024, type=int)\n",
    "parser.add_argument('--target_embed_dimension', default=1024, type=int)\n",
    "parser.add_argument('--patchsize', default=3, type=int)\n",
    "parser.add_argument('--coreset_rate', default=0.1, type=float) # 연산량에 큰 영향을 주는 파라미터 (0.01 - 0.25)\n",
    "parser.add_argument('--anomaly_scorer_num_nn', default=1, type=int)\n",
    "parser.add_argument('--batch_size', default=2, type=int)\n",
    "parser.add_argument('--batch_size_inf', default=6, type=int) # 실제 capacitor cap 데이터의 열에 일치하도록 임의 설정\n",
    "parser.add_argument('--augment', default=True, type=bool)\n",
    "parser.add_argument('--seed', default=0, type=int) \n",
    "parser.add_argument('--device', nargs='+', default=[0], type=int)\n",
    "parser.add_argument('--num_workers', default=0, type=int)\n",
    "args = parser.parse_args('')\n",
    "\n",
    "image_size = args.image_size\n",
    "resize = args.resize\n",
    "BATCH_SIZE = args.batch_size\n",
    "BATCH_SIZE_INF = args.batch_size_inf\n",
    "SEED = args.seed\n",
    "\n",
    "# create save path\n",
    "save_root = \"saved\"\n",
    "if not os.path.exists(save_root):\n",
    "    os.mkdir(save_root)\n",
    "\n",
    "# set random seeds\n",
    "def set_seeds(seed=SEED):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    pl.seed_everything(SEED)\n",
    "\n",
    "set_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyDataset(Dataset):\n",
    "    def __init__(self, transform=None, dir=\"../Data/mvtec/screw/train/good\", test=False):\n",
    "        super().__init__()\n",
    "        self.test = test        \n",
    "        self.transform = transform\n",
    "        self.list_dir = sorted(glob.glob(os.path.join(dir, \"*.png\")))\n",
    "        self.list_data = []\n",
    "        if test: self.list_original_data = []\n",
    "\n",
    "        for idx, dir in enumerate(self.list_dir):\n",
    "            x = Image.open(dir).convert(\"RGB\")\n",
    "            if test: self.list_original_data.append(x)\n",
    "            if self.transform: x = self.transform(x)\n",
    "            self.list_data.append(x)\n",
    "        \n",
    "        print(f\"num_data: {len(self.list_data)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_dir)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.list_data[idx]\n",
    "        return {\"image\": x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "class DatasetSplit(Enum):\n",
    "    TRAIN = \"train\"\n",
    "    TEST = \"test\"\n",
    "\n",
    "class AnomalyDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 source=\"D:/Dev/Data/mvtec/screw\",\n",
    "                 anomaly_source_path=\"D:/Dev/Data/dtd/images\",\n",
    "                 # dataset_name='mvtec',\n",
    "                 # classname='screw',\n",
    "                 resize=288,\n",
    "                 imagesize=288,\n",
    "                 split=DatasetSplit.TRAIN,\n",
    "                 rotate_degrees=0,\n",
    "                 translate=0,\n",
    "                 brightness_factor=0,\n",
    "                 contrast_factor=0,\n",
    "                 saturation_factor=0,\n",
    "                 gray_p=0,\n",
    "                 h_flip_p=0,\n",
    "                 v_flip_p=0,\n",
    "                 distribution=0,\n",
    "                 mean=0.5,\n",
    "                 std=0.1,\n",
    "                 fg=0,\n",
    "                 rand_aug=1,\n",
    "                 downsampling=8,\n",
    "                 scale=0,\n",
    "                 batch_size=8):\n",
    "        super().__init__()\n",
    "        self.source = source\n",
    "        self.split = split\n",
    "        self.batch_size = batch_size\n",
    "        self.distribution = distribution\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.fg = fg\n",
    "        self.rand_aug = rand_aug\n",
    "        self.downsampling = downsampling\n",
    "        self.resize = resize if self.distribution != 1 else [resize, resize]\n",
    "        self.imgsize = imagesize\n",
    "        self.imagesize = (3, self.imgsize, self.imgsize)\n",
    "        # self.classname = classname\n",
    "        # self.dataset_name = dataset_name\n",
    "\n",
    "        self.imgpaths, self.data_to_iterate = self.get_image_data()\n",
    "        self.anomaly_source_paths = sorted(1 * glob.glob(anomaly_source_path + \"/*/*.jpg\") +\n",
    "                                           0 * list(self.imgpaths.values())[0])\n",
    "\n",
    "        self.transform_img = [\n",
    "            transforms.Resize(self.resize),\n",
    "            transforms.ColorJitter(brightness_factor, contrast_factor, saturation_factor),\n",
    "            transforms.RandomHorizontalFlip(h_flip_p),\n",
    "            transforms.RandomVerticalFlip(v_flip_p),\n",
    "            transforms.RandomGrayscale(gray_p),\n",
    "            transforms.RandomAffine(rotate_degrees,\n",
    "                                    translate=(translate, translate),\n",
    "                                    scale=(1.0 - scale, 1.0 + scale),\n",
    "                                    interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "            transforms.CenterCrop(self.imgsize),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "        ]\n",
    "        self.transform_img = transforms.Compose(self.transform_img)\n",
    "\n",
    "        self.transform_mask = [\n",
    "            transforms.Resize(self.resize),\n",
    "            transforms.CenterCrop(self.imgsize),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "        self.transform_mask = transforms.Compose(self.transform_mask)\n",
    "\n",
    "    def rand_augmenter(self):\n",
    "        list_aug = [\n",
    "            transforms.ColorJitter(contrast=(0.8, 1.2)),\n",
    "            transforms.ColorJitter(brightness=(0.8, 1.2)),\n",
    "            transforms.ColorJitter(saturation=(0.8, 1.2), hue=(-0.2, 0.2)),\n",
    "            transforms.RandomHorizontalFlip(p=1),\n",
    "            transforms.RandomVerticalFlip(p=1),\n",
    "            transforms.RandomGrayscale(p=1),\n",
    "            transforms.RandomAutocontrast(p=1),\n",
    "            transforms.RandomEqualize(p=1),\n",
    "            transforms.RandomAffine(degrees=(-45, 45)),\n",
    "        ]\n",
    "        aug_idx = np.random.choice(np.arange(len(list_aug)), 3, replace=False)\n",
    "\n",
    "        transform_aug = [\n",
    "            transforms.Resize(self.resize),\n",
    "            list_aug[aug_idx[0]],\n",
    "            list_aug[aug_idx[1]],\n",
    "            list_aug[aug_idx[2]],\n",
    "            transforms.CenterCrop(self.imgsize),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "        ]\n",
    "\n",
    "        transform_aug = transforms.Compose(transform_aug)\n",
    "        return transform_aug\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # TEST, anomaly != \"good\": [anomaly, img_path, maskpath]\n",
    "        # else: [anomaly, img_path, None]\n",
    "        anomaly, image_path, mask_path = self.data_to_iterate[idx] # [anomaly유형, img경로]\n",
    "        image = PIL.Image.open(image_path).convert(\"RGB\")\n",
    "        image = self.transform_img(image)\n",
    "        \n",
    "        mask_fg = mask_s = aug_image = torch.tensor([1])\n",
    "        if self.split == DatasetSplit.TRAIN:\n",
    "            aug = PIL.Image.open(np.random.choice(self.anomaly_source_paths)).convert(\"RGB\")\n",
    "            if self.rand_aug:\n",
    "                transform_aug = self.rand_augmenter()\n",
    "                aug = transform_aug(aug)\n",
    "            else:\n",
    "                aug = self.transform_img(aug)\n",
    "\n",
    "            mask_all = perlin_mask(image.shape, self.imgsize // self.downsampling, 0, 6, mask_fg, 1)\n",
    "            mask_s = torch.from_numpy(mask_all[0])\n",
    "            mask_l = torch.from_numpy(mask_all[1])\n",
    "\n",
    "            beta = np.random.normal(loc=self.mean, scale=self.std)\n",
    "            beta = np.clip(beta, .2, .8)\n",
    "            aug_image = image * (1 - mask_l) + (1 - beta) * aug * mask_l + beta * image * mask_l\n",
    "\n",
    "        if self.split == DatasetSplit.TEST and mask_path is not None:\n",
    "            mask_gt = PIL.Image.open(mask_path).convert('L')\n",
    "            mask_gt = self.transform_mask(mask_gt)\n",
    "        else:\n",
    "            mask_gt = torch.zeros([1, *image.size()[1:]])\n",
    "\n",
    "        # print(f\"image: {image.shape} mask_gt: {mask_gt.shape}\") # [3, 288, 288] [1, 288, 288]\n",
    "\n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"aug\": aug_image,\n",
    "            \"mask_s\": mask_s,\n",
    "            \"mask_gt\": mask_gt,\n",
    "            \"is_anomaly\": int(anomaly != \"good\"),\n",
    "            \"image_path\": image_path,\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_to_iterate)\n",
    "    \n",
    "    def get_image_data(self):\n",
    "        imgpaths = {}\n",
    "        maskpaths = {}\n",
    "\n",
    "        classpath = os.path.join(self.source, self.split.value)\n",
    "        maskpath = os.path.join(self.source, \"ground_truth\")\n",
    "        anomaly_types = os.listdir(classpath)\n",
    "\n",
    "        for anomaly in anomaly_types:\n",
    "            anomaly_path = os.path.join(classpath, anomaly)\n",
    "            anomaly_files = sorted(os.listdir(anomaly_path))\n",
    "            imgpaths[anomaly] = [os.path.join(anomaly_path, x) for x in anomaly_files]\n",
    "\n",
    "            if self.split == DatasetSplit.TEST and anomaly != \"good\":\n",
    "                anomaly_mask_path = os.path.join(maskpath, anomaly)\n",
    "                anomaly_mask_files = sorted(os.listdir(anomaly_mask_path))\n",
    "                maskpaths[anomaly] = [os.path.join(anomaly_mask_path, x) for x in anomaly_mask_files]\n",
    "            else:\n",
    "                maskpaths[\"good\"] = None\n",
    "\n",
    "        data_to_iterate = []\n",
    "        # for classname in sorted(imgpaths_per_class.keys()):\n",
    "        for anomaly in sorted(imgpaths.keys()):\n",
    "            for i, image_path in enumerate(imgpaths[anomaly]):\n",
    "                # data_tuple = [classname, anomaly, image_path]\n",
    "                data_tuple = [anomaly, image_path]\n",
    "                if self.split == DatasetSplit.TEST and anomaly != \"good\":\n",
    "                    data_tuple.append(maskpaths[anomaly][i])\n",
    "                else:\n",
    "                    data_tuple.append(None)\n",
    "                data_to_iterate.append(data_tuple)\n",
    "\n",
    "        return imgpaths, data_to_iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AnomalyDataset(\n",
    "    source=\"D:/Dev/Data/mvtec/screw\",\n",
    "    anomaly_source_path=\"D:/Dev/Data/dtd/images\",\n",
    "    resize=288,\n",
    "    imagesize=288,\n",
    "    split=DatasetSplit.TRAIN,\n",
    "    rotate_degrees=0,\n",
    "    translate=0,\n",
    "    brightness_factor=0,\n",
    "    contrast_factor=0,\n",
    "    saturation_factor=0,\n",
    "    gray_p=0,\n",
    "    h_flip_p=0,\n",
    "    v_flip_p=0,\n",
    "    distribution=0,\n",
    "    mean=0.5,\n",
    "    std=0.1,\n",
    "    fg=0,\n",
    "    rand_aug=1,\n",
    "    downsampling=8,\n",
    "    scale=0,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    # prefetch_factor=2,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = AnomalyDataset(\n",
    "    source=\"D:/Dev/Data/mvtec/screw\",\n",
    "    anomaly_source_path=\"D:/Dev/Data/dtd/images\",\n",
    "    resize=288,\n",
    "    imagesize=288,\n",
    "    split=DatasetSplit.TEST,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    # prefetch_factor=2,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = utils.set_torch_device(gpu_ids=args.device)\n",
    "model = glass.GLASS(device)\n",
    "\n",
    "backbone = backbones.load(args.backbone)\n",
    "backbone.name, backbone.seed = args.backbone, None\n",
    "\n",
    "model.load(\n",
    "    backbone                 = backbone,\n",
    "    layers_to_extract_from   = args.layers_to_extract_from,\n",
    "    device                   = device,\n",
    "    input_shape              = (3, image_size, image_size), ##\n",
    "    pretrain_embed_dimension = args.pretrain_embed_dimension,\n",
    "    target_embed_dimension   = args.target_embed_dimension,\n",
    "    patchsize                = args.patchsize,\n",
    ")\n",
    "\n",
    "# 저장 경로 설정\n",
    "save_path = \"saved\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "models_dir = os.path.join(save_path, \"models\")\n",
    "model.set_model_dir(os.path.join(models_dir, f\"backbone\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:19 loss:9.88e-02 pt:98.83 pf:97.85 rt:1.52 rg:1.34 rf:2.57 svd:0 sample:248 IAUC:95.04(95.49) IAP:0.0(0.0) PAUC:99.22(99.24) PAP:0.0(0.0) PRO:0.0(0.0) E:18(15):   3%|▎         | 19/640 [28:51<14:53:33, 86.33s/epoch]"
     ]
    }
   ],
   "source": [
    "# train\n",
    "flag = model.trainer(train_dataloader, test_dataloader)\n",
    "\n",
    "# save model\n",
    "model.save_to_path(save_path=save_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load model\n",
    "# model.load_from_path(load_path=save_root, \n",
    "#                           device=device, \n",
    "#                           nn_method=common.FaissNN(on_gpu=True, num_workers=8))\n",
    "\n",
    "# # validate -> threshold 설정을 위해 validation 수행\n",
    "# scores, _ = model.predict(valid_dataloader)\n",
    "\n",
    "# # set threshold\n",
    "# threshold = np.max(scores)\n",
    "# print(f\"threshold: {threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# fault classes\n",
    "# screw: manipulated_front | scratch_head | scratch_neck | thread_side | thread_top\n",
    "# bottle: broken_large | broken_small | contamination\n",
    "# metal_nut: bent | color | flip | scratch\n",
    "# \"\"\"\n",
    "# test_dataset = AnomalyDataset(dir=\"../Data/mvtec/bottle/test/broken_large\", transform=test_transform, test=True)\n",
    "# test_dataloader = DataLoader(test_dataset, \n",
    "#                              batch_size=BATCH_SIZE_INF, \n",
    "#                              shuffle=False, \n",
    "#                              num_workers=args.num_workers,\n",
    "#                              pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_list = []\n",
    "# seg_list = []\n",
    "\n",
    "# # inference\n",
    "# start = time.time()\n",
    "# scores, seg = model.predict(test_dataloader)\n",
    "# print(f\"Avg Prediction Time: {(time.time() - start) / (len(test_dataloader) * BATCH_SIZE_INF) :.6f}\")\n",
    "\n",
    "# scores_list.append(scores)\n",
    "# seg_list.append(seg)\n",
    "\n",
    "# scores = np.max(scores_list, axis=0)\n",
    "# prediction = np.where(scores < threshold, 0, 1)\n",
    "\n",
    "# print(f\"n_anomaly: {np.sum(prediction)} / {scores.shape[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scores = np.array(scores_list)\n",
    "# # min_scores = scores.min(axis=-1).reshape(-1, 1)\n",
    "# # max_scores = scores.max(axis=-1).reshape(-1, 1)\n",
    "# # scores = (scores - min_scores) / (max_scores - min_scores)\n",
    "# # scores = np.mean(scores, axis=0)\n",
    "\n",
    "# segmentations = np.array(seg_list)\n",
    "# min_scores = (segmentations.reshape(len(segmentations), -1).min(axis=-1).reshape(-1, 1, 1, 1))\n",
    "# max_scores = (segmentations.reshape(len(segmentations), -1).max(axis=-1).reshape(-1, 1, 1, 1))\n",
    "# segmentations = (segmentations - min_scores) / (max_scores - min_scores)\n",
    "# segmentations = np.mean(segmentations, axis=0)\n",
    "\n",
    "# # imgs = [np.transpose(x, (1, 2, 0)) for x in test_dataset.list_original_data]\n",
    "# imgs = [x for x in test_dataset.list_original_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(len(imgs)):\n",
    "#     f, axes = plt.subplots(1, 2)\n",
    "#     axes[0].imshow(imgs[idx])\n",
    "#     axes[1].imshow(segmentations[idx])\n",
    "#     f.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
