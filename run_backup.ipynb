{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qlee\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import common\n",
    "import sampler\n",
    "import glass\n",
    "import backbones\n",
    "import utils\n",
    "\n",
    "from perlin import perlin_mask\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import PIL\n",
    "from enum import Enum\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    }
   ],
   "source": [
    "from argparse import ArgumentParser\n",
    "\n",
    "parser = ArgumentParser(description=\"patchcore\")\n",
    "parser.add_argument('--image_size', default=288, type=int) # 288\n",
    "parser.add_argument('--resize', default=288, type=int) # 288\n",
    "parser.add_argument('--backbone', default='wideresnet50', type=str) \n",
    "parser.add_argument('--layers_to_extract_from', nargs='+', default=['layer2', 'layer3'], type=str) # 연산량에 큰 영향을 주는 파라미터 (성능만 괜찮으면 layer를 일부 제거해도 무방)\n",
    "parser.add_argument('--pretrain_embed_dimension', default=1024, type=int)\n",
    "parser.add_argument('--target_embed_dimension', default=1024, type=int)\n",
    "parser.add_argument('--patchsize', default=3, type=int)\n",
    "parser.add_argument('--coreset_rate', default=0.1, type=float) # 연산량에 큰 영향을 주는 파라미터 (0.01 - 0.25)\n",
    "parser.add_argument('--anomaly_scorer_num_nn', default=1, type=int)\n",
    "parser.add_argument('--batch_size', default=2, type=int)\n",
    "parser.add_argument('--batch_size_inf', default=6, type=int) # 실제 capacitor cap 데이터의 열에 일치하도록 임의 설정\n",
    "parser.add_argument('--augment', default=True, type=bool)\n",
    "parser.add_argument('--seed', default=0, type=int) \n",
    "parser.add_argument('--device', nargs='+', default=[0], type=int)\n",
    "parser.add_argument('--num_workers', default=0, type=int)\n",
    "args = parser.parse_args('')\n",
    "\n",
    "image_size = args.image_size\n",
    "resize = args.resize\n",
    "BATCH_SIZE = args.batch_size\n",
    "BATCH_SIZE_INF = args.batch_size_inf\n",
    "SEED = args.seed\n",
    "\n",
    "# create save path\n",
    "save_root = \"saved\"\n",
    "if not os.path.exists(save_root):\n",
    "    os.mkdir(save_root)\n",
    "\n",
    "# set random seeds\n",
    "def set_seeds(seed=SEED):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    pl.seed_everything(SEED)\n",
    "\n",
    "set_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyDataset(Dataset):\n",
    "    def __init__(self, transform=None, dir=\"../Data/mvtec/screw/train/good\", test=False):\n",
    "        super().__init__()\n",
    "        self.test = test        \n",
    "        self.transform = transform\n",
    "        self.list_dir = sorted(glob.glob(os.path.join(dir, \"*.png\")))\n",
    "        self.list_data = []\n",
    "        if test: self.list_original_data = []\n",
    "\n",
    "        for idx, dir in enumerate(self.list_dir):\n",
    "            x = Image.open(dir).convert(\"RGB\")\n",
    "            if test: self.list_original_data.append(x)\n",
    "            if self.transform: x = self.transform(x)\n",
    "            self.list_data.append(x)\n",
    "        \n",
    "        print(f\"num_data: {len(self.list_data)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_dir)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.list_data[idx]\n",
    "        return {\"image\": x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "class DatasetSplit(Enum):\n",
    "    TRAIN = \"train\"\n",
    "    TEST = \"test\"\n",
    "\n",
    "class AnomalyDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 source=\"D:/Dev/Data/mvtec/screw\",\n",
    "                 anomaly_source_path=\"D:/Dev/Data/dtd/images\",\n",
    "                 # dataset_name='mvtec',\n",
    "                 # classname='screw',\n",
    "                 resize=288,\n",
    "                 imagesize=288,\n",
    "                 split=DatasetSplit.TRAIN,\n",
    "                 rotate_degrees=0,\n",
    "                 translate=0,\n",
    "                 brightness_factor=0,\n",
    "                 contrast_factor=0,\n",
    "                 saturation_factor=0,\n",
    "                 gray_p=0,\n",
    "                 h_flip_p=0,\n",
    "                 v_flip_p=0,\n",
    "                 distribution=0,\n",
    "                 mean=0.5,\n",
    "                 std=0.1,\n",
    "                 fg=0,\n",
    "                 rand_aug=1,\n",
    "                 downsampling=8,\n",
    "                 scale=0,\n",
    "                 batch_size=8):\n",
    "        super().__init__()\n",
    "        self.source = source\n",
    "        self.split = split\n",
    "        self.batch_size = batch_size\n",
    "        self.distribution = distribution\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.fg = fg\n",
    "        self.rand_aug = rand_aug\n",
    "        self.downsampling = downsampling\n",
    "        self.resize = resize if self.distribution != 1 else [resize, resize]\n",
    "        self.imgsize = imagesize\n",
    "        self.imagesize = (3, self.imgsize, self.imgsize)\n",
    "        # self.classname = classname\n",
    "        # self.dataset_name = dataset_name\n",
    "\n",
    "        self.imgpaths, self.data_to_iterate = self.get_image_data()\n",
    "        self.anomaly_source_paths = sorted(1 * glob.glob(anomaly_source_path + \"/*/*.jpg\") +\n",
    "                                           0 * list(self.imgpaths.values())[0])\n",
    "\n",
    "        self.transform_img = [\n",
    "            transforms.Resize(self.resize),\n",
    "            transforms.ColorJitter(brightness_factor, contrast_factor, saturation_factor),\n",
    "            transforms.RandomHorizontalFlip(h_flip_p),\n",
    "            transforms.RandomVerticalFlip(v_flip_p),\n",
    "            transforms.RandomGrayscale(gray_p),\n",
    "            transforms.RandomAffine(rotate_degrees,\n",
    "                                    translate=(translate, translate),\n",
    "                                    scale=(1.0 - scale, 1.0 + scale),\n",
    "                                    interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "            transforms.CenterCrop(self.imgsize),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "        ]\n",
    "        self.transform_img = transforms.Compose(self.transform_img)\n",
    "\n",
    "        self.transform_mask = [\n",
    "            transforms.Resize(self.resize),\n",
    "            transforms.CenterCrop(self.imgsize),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "        self.transform_mask = transforms.Compose(self.transform_mask)\n",
    "\n",
    "    def rand_augmenter(self):\n",
    "        list_aug = [\n",
    "            transforms.ColorJitter(contrast=(0.8, 1.2)),\n",
    "            transforms.ColorJitter(brightness=(0.8, 1.2)),\n",
    "            transforms.ColorJitter(saturation=(0.8, 1.2), hue=(-0.2, 0.2)),\n",
    "            transforms.RandomHorizontalFlip(p=1),\n",
    "            transforms.RandomVerticalFlip(p=1),\n",
    "            transforms.RandomGrayscale(p=1),\n",
    "            transforms.RandomAutocontrast(p=1),\n",
    "            transforms.RandomEqualize(p=1),\n",
    "            transforms.RandomAffine(degrees=(-45, 45)),\n",
    "        ]\n",
    "        aug_idx = np.random.choice(np.arange(len(list_aug)), 3, replace=False)\n",
    "\n",
    "        transform_aug = [\n",
    "            transforms.Resize(self.resize),\n",
    "            list_aug[aug_idx[0]],\n",
    "            list_aug[aug_idx[1]],\n",
    "            list_aug[aug_idx[2]],\n",
    "            transforms.CenterCrop(self.imgsize),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "        ]\n",
    "\n",
    "        transform_aug = transforms.Compose(transform_aug)\n",
    "        return transform_aug\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # TEST, anomaly != \"good\": [anomaly, img_path, maskpath]\n",
    "        # else: [anomaly, img_path, None]\n",
    "        anomaly, image_path, mask_path = self.data_to_iterate[idx] # [anomaly유형, img경로]\n",
    "        image = PIL.Image.open(image_path).convert(\"RGB\")\n",
    "        image = self.transform_img(image)\n",
    "        \n",
    "        mask_fg = mask_s = aug_image = torch.tensor([1])\n",
    "        if self.split == DatasetSplit.TRAIN:\n",
    "            aug = PIL.Image.open(np.random.choice(self.anomaly_source_paths)).convert(\"RGB\")\n",
    "            if self.rand_aug:\n",
    "                transform_aug = self.rand_augmenter()\n",
    "                aug = transform_aug(aug)\n",
    "            else:\n",
    "                aug = self.transform_img(aug)\n",
    "\n",
    "            mask_all = perlin_mask(image.shape, self.imgsize // self.downsampling, 0, 6, mask_fg, 1)\n",
    "            mask_s = torch.from_numpy(mask_all[0])\n",
    "            mask_l = torch.from_numpy(mask_all[1])\n",
    "\n",
    "            beta = np.random.normal(loc=self.mean, scale=self.std)\n",
    "            beta = np.clip(beta, .2, .8)\n",
    "            aug_image = image * (1 - mask_l) + (1 - beta) * aug * mask_l + beta * image * mask_l\n",
    "\n",
    "        if self.split == DatasetSplit.TEST and mask_path is not None:\n",
    "            mask_gt = PIL.Image.open(mask_path).convert('L')\n",
    "            mask_gt = self.transform_mask(mask_gt)\n",
    "        else:\n",
    "            mask_gt = torch.zeros([1, *image.size()[1:]])\n",
    "\n",
    "        # print(f\"image: {image.shape} mask_gt: {mask_gt.shape}\") # [3, 288, 288] [1, 288, 288]\n",
    "\n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"aug\": aug_image,\n",
    "            \"mask_s\": mask_s,\n",
    "            \"mask_gt\": mask_gt,\n",
    "            \"is_anomaly\": int(anomaly != \"good\"),\n",
    "            \"image_path\": image_path,\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_to_iterate)\n",
    "    \n",
    "    def get_image_data(self):\n",
    "        imgpaths = {}\n",
    "        maskpaths = {}\n",
    "\n",
    "        classpath = os.path.join(self.source, self.split.value)\n",
    "        # maskpath = os.path.join(self.source, \"ground_truth\")\n",
    "        anomaly_types = os.listdir(classpath)\n",
    "\n",
    "        for anomaly in anomaly_types:\n",
    "            anomaly_path = os.path.join(classpath, anomaly)\n",
    "            anomaly_files = sorted(os.listdir(anomaly_path))\n",
    "            imgpaths[anomaly] = [os.path.join(anomaly_path, x) for x in anomaly_files]\n",
    "\n",
    "            if self.split == DatasetSplit.TEST and anomaly != \"good\":\n",
    "                # anomaly_mask_path = os.path.join(maskpath, anomaly)\n",
    "                # anomaly_mask_files = sorted(os.listdir(anomaly_mask_path))\n",
    "                # maskpaths[anomaly] = [os.path.join(anomaly_mask_path, x) for x in anomaly_mask_files]\n",
    "            else:\n",
    "                maskpaths[\"good\"] = None\n",
    "\n",
    "        data_to_iterate = []\n",
    "        # for classname in sorted(imgpaths_per_class.keys()):\n",
    "        for anomaly in sorted(imgpaths.keys()):\n",
    "            for i, image_path in enumerate(imgpaths[anomaly]):\n",
    "                # data_tuple = [classname, anomaly, image_path]\n",
    "                data_tuple = [anomaly, image_path]\n",
    "                if self.split == DatasetSplit.TEST and anomaly != \"good\":\n",
    "                    data_tuple.append(maskpaths[anomaly][i])\n",
    "                else:\n",
    "                    data_tuple.append(None)\n",
    "                data_to_iterate.append(data_tuple)\n",
    "\n",
    "        return imgpaths, data_to_iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AnomalyDataset(\n",
    "    source=\"D:/Dev/Data/mvtec/speefox\",\n",
    "    anomaly_source_path=\"D:/Dev/Data/dtd/images\",\n",
    "    resize=960,\n",
    "    imagesize=960,\n",
    "    split=DatasetSplit.TRAIN,\n",
    "    rotate_degrees=0,\n",
    "    translate=0,\n",
    "    brightness_factor=0,\n",
    "    contrast_factor=0,\n",
    "    saturation_factor=0,\n",
    "    gray_p=0,\n",
    "    h_flip_p=0,\n",
    "    v_flip_p=0,\n",
    "    distribution=0,\n",
    "    mean=0.5,\n",
    "    std=0.1,\n",
    "    fg=0,\n",
    "    rand_aug=1,\n",
    "    downsampling=8,\n",
    "    scale=0,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    # prefetch_factor=2,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: 'D:/Dev/Data/mvtec/speefox\\\\ground_truth\\\\test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mAnomalyDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:/Dev/Data/mvtec/speefox\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43manomaly_source_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:/Dev/Data/dtd/images\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m960\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimagesize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m960\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDatasetSplit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTEST\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m     10\u001b[0m     test_dataset,\n\u001b[0;32m     11\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     16\u001b[0m )\n",
      "Cell \u001b[1;32mIn[4], line 49\u001b[0m, in \u001b[0;36mAnomalyDataset.__init__\u001b[1;34m(self, source, anomaly_source_path, resize, imagesize, split, rotate_degrees, translate, brightness_factor, contrast_factor, saturation_factor, gray_p, h_flip_p, v_flip_p, distribution, mean, std, fg, rand_aug, downsampling, scale, batch_size)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimagesize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgsize, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgsize)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# self.classname = classname\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# self.dataset_name = dataset_name\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgpaths, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_to_iterate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manomaly_source_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(anomaly_source_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/*/*.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m     51\u001b[0m                                    \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgpaths\u001b[38;5;241m.\u001b[39mvalues())[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_img \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     54\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresize),\n\u001b[0;32m     55\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mColorJitter(brightness_factor, contrast_factor, saturation_factor),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39mIMAGENET_MEAN, std\u001b[38;5;241m=\u001b[39mIMAGENET_STD),\n\u001b[0;32m     66\u001b[0m ]\n",
      "Cell \u001b[1;32mIn[4], line 162\u001b[0m, in \u001b[0;36mAnomalyDataset.get_image_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit \u001b[38;5;241m==\u001b[39m DatasetSplit\u001b[38;5;241m.\u001b[39mTEST \u001b[38;5;129;01mand\u001b[39;00m anomaly \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgood\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    161\u001b[0m     anomaly_mask_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(maskpath, anomaly)\n\u001b[1;32m--> 162\u001b[0m     anomaly_mask_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43manomaly_mask_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    163\u001b[0m     maskpaths[anomaly] \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(anomaly_mask_path, x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m anomaly_mask_files]\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: 'D:/Dev/Data/mvtec/speefox\\\\ground_truth\\\\test'"
     ]
    }
   ],
   "source": [
    "test_dataset = AnomalyDataset(\n",
    "    source=\"D:/Dev/Data/mvtec/speefox\",\n",
    "    anomaly_source_path=\"D:/Dev/Data/dtd/images\",\n",
    "    resize=960,\n",
    "    imagesize=960,\n",
    "    split=DatasetSplit.TEST,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    # prefetch_factor=2,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = utils.set_torch_device(gpu_ids=args.device)\n",
    "model = glass.GLASS(device)\n",
    "\n",
    "backbone = backbones.load(args.backbone)\n",
    "backbone.name, backbone.seed = args.backbone, None\n",
    "\n",
    "model.load(\n",
    "    backbone                 = backbone,\n",
    "    layers_to_extract_from   = args.layers_to_extract_from,\n",
    "    device                   = device,\n",
    "    input_shape              = (3, image_size, image_size), ##\n",
    "    pretrain_embed_dimension = args.pretrain_embed_dimension,\n",
    "    target_embed_dimension   = args.target_embed_dimension,\n",
    "    patchsize                = args.patchsize,\n",
    ")\n",
    "\n",
    "# 저장 경로 설정\n",
    "save_path = \"saved\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "models_dir = os.path.join(save_path, \"models\")\n",
    "model.set_model_dir(os.path.join(models_dir, f\"backbone\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "flag = model.trainer(train_dataloader, test_dataloader)\n",
    "\n",
    "# save model\n",
    "i_auroc, i_ap, p_auroc, p_ap, p_pro, epoch = model.tester(test_dataloader, dataset_name)\n",
    "result_collect.append(\n",
    "    {\n",
    "        \"dataset_name\": dataset_name,\n",
    "        \"image_auroc\": i_auroc,\n",
    "        \"image_ap\": i_ap,\n",
    "        \"pixel_auroc\": p_auroc,\n",
    "        \"pixel_ap\": p_ap,\n",
    "        \"pixel_pro\": p_pro,\n",
    "        \"best_epoch\": epoch,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load model\n",
    "# model.load_from_path(load_path=save_root, \n",
    "#                           device=device, \n",
    "#                           nn_method=common.FaissNN(on_gpu=True, num_workers=8))\n",
    "\n",
    "# # validate -> threshold 설정을 위해 validation 수행\n",
    "# scores, _ = model.predict(valid_dataloader)\n",
    "\n",
    "# # set threshold\n",
    "# threshold = np.max(scores)\n",
    "# print(f\"threshold: {threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# fault classes\n",
    "# screw: manipulated_front | scratch_head | scratch_neck | thread_side | thread_top\n",
    "# bottle: broken_large | broken_small | contamination\n",
    "# metal_nut: bent | color | flip | scratch\n",
    "# \"\"\"\n",
    "# test_dataset = AnomalyDataset(dir=\"../Data/mvtec/bottle/test/broken_large\", transform=test_transform, test=True)\n",
    "# test_dataloader = DataLoader(test_dataset, \n",
    "#                              batch_size=BATCH_SIZE_INF, \n",
    "#                              shuffle=False, \n",
    "#                              num_workers=args.num_workers,\n",
    "#                              pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_list = []\n",
    "# seg_list = []\n",
    "\n",
    "# # inference\n",
    "# start = time.time()\n",
    "# scores, seg = model.predict(test_dataloader)\n",
    "# print(f\"Avg Prediction Time: {(time.time() - start) / (len(test_dataloader) * BATCH_SIZE_INF) :.6f}\")\n",
    "\n",
    "# scores_list.append(scores)\n",
    "# seg_list.append(seg)\n",
    "\n",
    "# scores = np.max(scores_list, axis=0)\n",
    "# prediction = np.where(scores < threshold, 0, 1)\n",
    "\n",
    "# print(f\"n_anomaly: {np.sum(prediction)} / {scores.shape[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scores = np.array(scores_list)\n",
    "# # min_scores = scores.min(axis=-1).reshape(-1, 1)\n",
    "# # max_scores = scores.max(axis=-1).reshape(-1, 1)\n",
    "# # scores = (scores - min_scores) / (max_scores - min_scores)\n",
    "# # scores = np.mean(scores, axis=0)\n",
    "\n",
    "# segmentations = np.array(seg_list)\n",
    "# min_scores = (segmentations.reshape(len(segmentations), -1).min(axis=-1).reshape(-1, 1, 1, 1))\n",
    "# max_scores = (segmentations.reshape(len(segmentations), -1).max(axis=-1).reshape(-1, 1, 1, 1))\n",
    "# segmentations = (segmentations - min_scores) / (max_scores - min_scores)\n",
    "# segmentations = np.mean(segmentations, axis=0)\n",
    "\n",
    "# # imgs = [np.transpose(x, (1, 2, 0)) for x in test_dataset.list_original_data]\n",
    "# imgs = [x for x in test_dataset.list_original_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(len(imgs)):\n",
    "#     f, axes = plt.subplots(1, 2)\n",
    "#     axes[0].imshow(imgs[idx])\n",
    "#     axes[1].imshow(segmentations[idx])\n",
    "#     f.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
